{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from datafed.CommandLib import API\n",
    "\n",
    "from util import get_metadata\n",
    "\n",
    "df_api = API()\n",
    "\n",
    "\n",
    "file_name = \"./test_data/HiGl_m750415.ibw\"\n",
    "collection_id = \"c/p_2022_afm_oxford_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = get_metadata(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_resp = df_api.collectionItemsList(\"c/p_2022_afm_oxford_root\", count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ls_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del json_output[\"Flatten Offsets 0\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del json_output[\"Flatten Slopes 0\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del json_output[\"Flatten Slopes 4\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del json_output[\"Flatten Offsets 4\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del json_output[\"Flatten Offsets 1\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del json_output[\"Flatten Slopes 1\"]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for i, (key, value) in enumerate(json_output.items()):\n",
    "    if value == np.NINF:\n",
    "        json_output[key] = \"-Inf\"\n",
    "\n",
    "for i, (key, value) in enumerate(json_output.items()):\n",
    "    if value == np.Inf:\n",
    "        json_output[key] = \"Inf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _send_ibw_to_datafed(file_name, collection_id):\n",
    "    df_api = API()\n",
    "\n",
    "    json_output = get_metadata(file_name)\n",
    "\n",
    "    # This removes flattening information and fixes inf values in metadata\n",
    "    try:\n",
    "        del json_output[\"Flatten Offsets 0\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del json_output[\"Flatten Slopes 0\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del json_output[\"Flatten Slopes 4\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del json_output[\"Flatten Offsets 4\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del json_output[\"Flatten Offsets 1\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del json_output[\"Flatten Slopes 1\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, (key, value) in enumerate(json_output.items()):\n",
    "        if value == np.NINF:\n",
    "            json_output[key] = \"-Inf\"\n",
    "\n",
    "    for i, (key, value) in enumerate(json_output.items()):\n",
    "        if value == np.Inf:\n",
    "            json_output[key] = \"Inf\"\n",
    "\n",
    "    try:\n",
    "        # creates a new data record\n",
    "        dc_resp = df_api.dataCreate(\n",
    "            os.path.basename(file_name),  # file name\n",
    "            # metadata=json.dumps(json_output), # metadata\n",
    "            parent_id=collection_id,  # parent collection\n",
    "        )\n",
    "    except Exception:\n",
    "        print(file_name)\n",
    "        print(json_output)\n",
    "        print(collection_id)\n",
    "        print(\"There was an error creating the DataRecord\")\n",
    "\n",
    "    try:\n",
    "        # extracts the record ID\n",
    "        rec_id = dc_resp[0].data[0].id\n",
    "    except ValueError:\n",
    "        print(\"Could not find record ID\")\n",
    "\n",
    "    try:\n",
    "        # sends the put command\n",
    "        df_api.dataPut(rec_id, file_name, wait=False)\n",
    "    except Exception:\n",
    "        print(\"Could not intiate globus transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "file_name = r\"C:\\Users\\Joshua Agar\\OneDrive - Drexel University\\Documents\\Data_Analysis\\AFM_to_DataFed\\test_data\"\n",
    "\n",
    "if os.path.isdir(file_name):\n",
    "    file_list = glob.glob(file_name + \"\\**\\*.ibw\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_resp = df_api.dataCreate(\n",
    "    os.path.basename(file_name),  # file name\n",
    "    metadata=json.dumps(json_output),  # metadata\n",
    "    parent_id=collection_id,  # parent collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_resp = df_api.dataCreate(\n",
    "    os.path.basename(file_name),  # file name\n",
    "    metadata=json.dumps(json_output),  # metadata\n",
    "    parent_id=collection_id,  # parent collection\n",
    ")\n",
    "\n",
    "rec_id = dc_resp[0].data[0].id\n",
    "\n",
    "put_resp = df_api.dataPut(rec_id, file_name, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (key, value) in enumerate(json_output.items()):\n",
    "#    #   if value == -inf:\n",
    "#         print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (obj, value) in enumerate(json_output.items()):\n",
    "    if obj == \"Flatten Offsets 0\":\n",
    "        json_output.pop(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "88c86ea0047df401248046be197d309eb99ce1c903ac1399c85c14d8513c3da5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
